import pandas as pd
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import roc_auc_score, accuracy_score
import mlflow
from mlflow.tracking import MlflowClient

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
MLFLOW_TRACKING_URI = "http://localhost:5000"
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
mlflow.set_experiment("Hospital Readmission Strategy Comparison")

FEAST_REPO_PATH = "../2/hospital_readmissions/feature_repo"
MODEL_NAME = "HospitalReadmissionModel-Batch"


def train_batch_model():
    print("--- –ó–∞–ø—É—Å–∫ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (Batch Training) ---")

    client = MlflowClient()

    # --- 1. –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ---
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ parquet —Ñ–∞–π–ª–∞...")

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ parquet —Ñ–∞–π–ª–∞
        df = pd.read_parquet(
            f'{FEAST_REPO_PATH}/data/patient_features.parquet')

        if df.empty:
            print("–û—à–∏–±–∫–∞: Parquet —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π")
            return

        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –∏–∑ parquet —Ñ–∞–π–ª–∞")

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ parquet —Ñ–∞–π–ª–∞: {e}")
        return

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    training_df = df.dropna()

    if training_df.empty:
        print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ NaN –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")
        return

    print(f"–û—Å—Ç–∞–ª–æ—Å—å {len(training_df)} –∑–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏")

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Ñ–∏—á–∏ –≤ one-hot encoding
    categorical_columns = ['gender', 'diabetes', 'hypertension',
                           'discharge_destination', 'bmi_category', 'age_group']

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –±–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Ñ–∏—á–∏
    binary_mapping = {'Yes': 1, 'No': 0}
    for col in ['diabetes', 'hypertension']:
        if col in training_df.columns:
            training_df[col] = training_df[col].map(binary_mapping).fillna(0)

    # One-hot encoding –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö —Ñ–∏—á
    training_df_encoded = pd.get_dummies(
        training_df, columns=categorical_columns, prefix=categorical_columns)

    # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    columns_to_drop = ['patient_id', 'event_timestamp',
                       'created_timestamp', 'readmitted_30_days']
    feature_columns = [col for col in training_df_encoded.columns
                       if col not in columns_to_drop]

    X_train = training_df_encoded[feature_columns]
    y_train = training_df_encoded['readmitted_30_days']

    print(
        f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö: X_train {X_train.shape}, y_train {y_train.shape}")
    print(
        f"–ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤: {y_train.value_counts(normalize=True).to_dict()}")
    print(f"üîß –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á: {len(feature_columns)}")

    # --- 2. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ---
    print("üîß –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ GradientBoosting –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏...")

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è GradientBoosting Classifier
    params = {
        'n_estimators': 100,
        'learning_rate': 0.1,
        'max_depth': 3,
        'min_samples_split': 2,
        'min_samples_leaf': 1,
        'subsample': 0.8,
        'random_state': 42
    }

    model = GradientBoostingClassifier(**params)

    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/validation –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    from sklearn.model_selection import train_test_split
    X_train_split, X_val, y_train_split, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
    )

    print(
        f"–û–±—É—á–µ–Ω–∏–µ –Ω–∞ {len(X_train_split)} samples, –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ {len(X_val)} samples")

    model.fit(X_train_split, y_train_split)

    # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
    y_pred_proba = model.predict_proba(X_val)[:, 1]
    y_pred = model.predict(X_val)

    auc = roc_auc_score(y_val, y_pred_proba)
    accuracy = accuracy_score(y_val, y_pred)

    print(
        f"–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞. Validation AUC: {auc:.4f}, Accuracy: {accuracy:.4f}")

    # --- 3. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ MLflow ---
    with mlflow.start_run(run_name="Batch Training Run") as run:
        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        mlflow.log_params(params)
        mlflow.log_param("training_samples", len(X_train))
        mlflow.log_param("feature_count", len(feature_columns))
        mlflow.log_param("data_source", "parquet_file")

        # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ (—Ç–æ–ª—å–∫–æ AUC –∏ Accuracy)
        mlflow.log_metrics({
            "val_auc": auc,
            "val_accuracy": accuracy,
            "train_auc": roc_auc_score(y_train_split, model.predict_proba(X_train_split)[:, 1]),
            "train_accuracy": accuracy_score(y_train_split, model.predict(X_train_split))
        })

        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö
        mlflow.log_param("class_balance", str(
            y_train.value_counts(normalize=True).to_dict()))
        mlflow.log_param("feature_names_count", len(feature_columns))

        # –õ–æ–≥–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
        input_example = X_train.head(5)
        signature = mlflow.models.infer_signature(
            input_example, model.predict(input_example))

        mlflow.sklearn.log_model(
            sk_model=model,
            artifact_path="model",
            registered_model_name=MODEL_NAME,
            input_example=input_example,
            signature=signature
        )

        model_uri = f"runs:/{run.info.run_id}/model"
        print(f"–ú–æ–¥–µ–ª—å –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞: {model_uri}")

        # --- 4. "–î–µ–ø–ª–æ–π" –≤ Staging (–¥–ª—è Canary) ---
        print("–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ –∏ –ø–µ—Ä–µ–≤–æ–¥ –≤ 'Staging'...")
        try:
            # –î–∞–µ–º –≤—Ä–µ–º—è MLflow –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å
            import time
            time.sleep(2)

            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–æ–∑–¥–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
            latest_version_info = client.get_latest_versions(
                MODEL_NAME, stages=["None"])[0]
            client.transition_model_version_stage(
                name=MODEL_NAME,
                version=latest_version_info.version,
                stage="Staging",
                archive_existing_versions=True  # –ê—Ä—Ö–∏–≤–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â—É—é –º–æ–¥–µ–ª—å –≤ Staging
            )
            print(
                f"–ú–æ–¥–µ–ª—å –≤–µ—Ä—Å–∏–∏ {latest_version_info.version} –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ 'Staging'.")

            # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–µ–ø–ª–æ–µ
            mlflow.log_param("deployed_version", latest_version_info.version)
            mlflow.log_param("deployment_stage", "Staging")

        except IndexError:
            print(
                f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π –º–æ–¥–µ–ª–∏ '{MODEL_NAME}' –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –≤ Staging.")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ –º–æ–¥–µ–ª–∏ –≤ Staging: {e}")

    print("–ü–∞–∫–µ—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")


if __name__ == "__main__":
    train_batch_model()
