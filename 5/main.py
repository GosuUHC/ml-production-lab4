# monitoring_pipeline.py

import os
import requests
import pandas as pd
import mlflow
from mlflow.tracking import MlflowClient
import datetime
import json
from evidently import Report
from evidently.presets import DataDriftPreset, ClassificationPreset
from evidently.legacy.pipeline.column_mapping import ColumnMapping

# --- 1. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ ---
MLFLOW_TRACKING_URI = os.getenv("MLFLOW_TRACKING_URI", "http://localhost:5000")
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
EXPERIMENT_NAME = "Hospital Readmission Monitoring"
mlflow.set_experiment(EXPERIMENT_NAME)

SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL")

# ÐŸÐ¾Ñ€Ð¾Ð³Ð¸ Ð´Ð»Ñ Ð±Ð¸Ð½Ð°Ñ€Ð½Ð¾Ð¹ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸
MODEL_PERFORMANCE_DEGRADATION_AUC_THRESHOLD = 0.95  # 5% Ð´ÐµÐ³Ñ€Ð°Ð´Ð°Ñ†Ð¸Ñ AUC
RETRAIN_PERFORMANCE_DEGRADATION_AUC_THRESHOLD = 0.90  # 10% Ð´ÐµÐ³Ñ€Ð°Ð´Ð°Ñ†Ð¸Ñ AUC
DATA_DRIFT_THRESHOLD = 0.5  # 50% ÑÐ¼ÐµÑ‰ÐµÐ½Ð½Ñ‹Ñ… Ñ„Ð¸Ñ‡

# --- 2. Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð´Ð»Ñ Ð°Ð»ÐµÑ€Ñ‚Ð¸Ð½Ð³Ð° ---


def send_alert(message: str, is_critical: bool = False):
    prefix = "ðŸš¨ *ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð°Ð»ÐµÑ€Ñ‚* ðŸš¨" if is_critical else "âš ï¸ *ÐŸÑ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ðµ* âš ï¸"
    full_message = f"{prefix}\n{message}"

    print(full_message)

    if not SLACK_WEBHOOK_URL:
        print("ÐŸÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ SLACK_WEBHOOK_URL Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð°. ÐÐ»ÐµÑ€Ñ‚ Ð½Ðµ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½ Ð² Slack.")
        return

    try:
        payload = {"blocks": [{"type": "section", "text": {
            "type": "mrkdwn", "text": full_message}}]}
        requests.post(SLACK_WEBHOOK_URL, json=payload, timeout=5)
        print("ÐÐ»ÐµÑ€Ñ‚ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½ Ð² Slack.")
    except Exception as e:
        print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐµ Ð°Ð»ÐµÑ€Ñ‚Ð° Ð² Slack: {e}")

# --- 3. Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° Ð´Ð»Ñ Ð±Ð¸Ð½Ð°Ñ€Ð½Ð¾Ð¹ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ ---


def monitor_data_drift(reference_data: pd.DataFrame, current_data: pd.DataFrame) -> dict:
    """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¾Ñ‚Ñ‡ÐµÑ‚ Ð¾ Ð´Ñ€Ð¸Ñ„Ñ‚Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ñ… Ñ„Ð¸Ñ‡."""
    print("\n--- Ð—Ð°Ð¿ÑƒÑÐº Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° Ð´Ñ€Ð¸Ñ„Ñ‚Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… ---")

    report = Report(metrics=[DataDriftPreset()])
    snapshot = report.run(reference_data=reference_data,
                          current_data=current_data)

    report_dict = json.loads(snapshot.json())

    try:
        drift_metric_value = report_dict['metrics'][0]['value']
        print(drift_metric_value)
        num_drifted_columns = int(drift_metric_value['count'])
        dataset_drift_detected = num_drifted_columns > 0

        # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚ ÑÐ¼ÐµÑ‰ÐµÐ½Ð½Ñ‹Ñ… Ñ„Ð¸Ñ‡
        total_columns = len(reference_data.columns)
        drift_percentage = num_drifted_columns / \
            total_columns if total_columns > 0 else 0

    except (KeyError, IndexError, TypeError) as e:
        print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð´Ñ€Ð¸Ñ„Ñ‚Ð° Ð¸Ð· Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°: {e}")
        return {"dataset_drift": False, "drifted_columns": 0, "drift_percentage": 0}

    with mlflow.start_run(run_name="Data Drift Report"):
        snapshot.save_html("data_drift_report.html")
        mlflow.log_artifact("data_drift_report.html", "reports")
        mlflow.log_dict(report_dict, "data_drift_report.json")

        mlflow.log_metric("num_drifted_columns", num_drifted_columns)
        mlflow.log_metric("drift_percentage", drift_percentage)
        mlflow.log_metric("dataset_drift", int(dataset_drift_detected))

    print(
        f"ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½ Ð´Ñ€Ð¸Ñ„Ñ‚ Ð² {num_drifted_columns} ÐºÐ¾Ð»Ð¾Ð½ÐºÐ°Ñ… ({drift_percentage:.1%})")

    if drift_percentage > DATA_DRIFT_THRESHOLD:
        send_alert(
            f"ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð´Ñ€Ð¸Ñ„Ñ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…! {drift_percentage:.1%} Ñ„Ð¸Ñ‡ ÑÐ¼ÐµÑ‰ÐµÐ½Ð¾ ({num_drifted_columns}/{total_columns}).",
            is_critical=True
        )
    elif dataset_drift_detected:
        send_alert(
            f"ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½ Ð´Ñ€Ð¸Ñ„Ñ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…! ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ¼ÐµÑ‰ÐµÐ½Ð½Ñ‹Ñ… ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº: {num_drifted_columns}.")

    return {
        "dataset_drift": dataset_drift_detected,
        "drifted_columns": num_drifted_columns,
        "drift_percentage": drift_percentage
    }


def monitor_model_performance(model, reference_data: pd.DataFrame, current_data: pd.DataFrame) -> dict:
    """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¾Ñ‚Ñ‡ÐµÑ‚ Ð¾ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ Ð±Ð¸Ð½Ð°Ñ€Ð½Ð¾Ð¹ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸."""
    print("\n--- Ð—Ð°Ð¿ÑƒÑÐº Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ---")

    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÐºÐ¾Ð¿Ð¸Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…
    ref_data_copy = reference_data.copy()
    curr_data_copy = current_data.copy()

    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ
    ref_predictions = model.predict(
        ref_data_copy.drop('readmitted_30_days', axis=1))
    curr_predictions = model.predict(
        curr_data_copy.drop('readmitted_30_days', axis=1))

    # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ evidently
    ref_data_copy['target'] = ref_data_copy['readmitted_30_days']
    curr_data_copy['target'] = curr_data_copy['readmitted_30_days']
    ref_data_copy.drop('readmitted_30_days', axis=1, inplace=True)
    curr_data_copy.drop('readmitted_30_days', axis=1, inplace=True)

    ref_data_copy['prediction'] = ref_predictions
    curr_data_copy['prediction'] = curr_predictions

    # ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ column mapping Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸
    from evidently.legacy.pipeline.column_mapping import TaskType

    column_mapping = ColumnMapping(
        target='target',
        prediction='prediction',
        task=TaskType.CLASSIFICATION_TASK
    )

    report = Report(metrics=[ClassificationPreset()])

    try:
        snapshot = report.run(
            reference_data=ref_data_copy,
            current_data=curr_data_copy,
            column_mapping=column_mapping
        )
    except Exception as e:
        print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð¾ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ðµ: {e}")
        return {"reference_auc": -1, "current_auc": -1, "reference_f1": -1, "current_f1": -1}

    report_dict = json.loads(snapshot.json())

    try:
        # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸
        quality_metrics = {}
        for metric in report_dict['metrics']:
            if metric['metric'] == 'ClassificationQualityMetric':
                quality_metrics = metric['result']
                break

        ref_auc = quality_metrics.get('reference', {}).get('roc_auc', -1)
        curr_auc = quality_metrics.get('current', {}).get('roc_auc', -1)
        ref_f1 = quality_metrics.get('reference', {}).get('f1', -1)
        curr_f1 = quality_metrics.get('current', {}).get('f1', -1)

    except (KeyError, IndexError) as e:
        print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸Ðº ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð¸Ð· Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°: {e}")
        print("--- Ð¡Ð¢Ð Ð£ÐšÐ¢Ð£Ð Ð JSON ÐžÐ¢Ð§Ð•Ð¢Ð Ðž ÐšÐÐ§Ð•Ð¡Ð¢Ð’Ð• ---")
        print(json.dumps(report_dict, indent=4))
        return {"reference_auc": -1, "current_auc": -1, "reference_f1": -1, "current_f1": -1}

    with mlflow.start_run(run_name="Model Performance Report"):
        snapshot.save_html("model_performance_report.html")
        mlflow.log_artifact("model_performance_report.html", "reports")
        mlflow.log_dict(report_dict, "model_performance_report.json")
        mlflow.log_metrics({
            "reference_auc": ref_auc,
            "current_auc": curr_auc,
            "reference_f1": ref_f1,
            "current_f1": curr_f1
        })

    print(f"Reference AUC: {ref_auc:.3f}, Current AUC: {curr_auc:.3f}")
    print(f"Reference F1: {ref_f1:.3f}, Current F1: {curr_f1:.3f}")

    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð´ÐµÐ³Ñ€Ð°Ð´Ð°Ñ†Ð¸ÑŽ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
    if ref_auc > 0 and curr_auc > 0:
        auc_ratio = curr_auc / ref_auc

        if auc_ratio < MODEL_PERFORMANCE_DEGRADATION_AUC_THRESHOLD:
            degradation = (1 - auc_ratio) * 100
            send_alert(
                f"ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð° Ð´ÐµÐ³Ñ€Ð°Ð´Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸! AUC ÑÐ½Ð¸Ð·Ð¸Ð»ÑÑ Ð½Ð° {degradation:.1f}% (Ñ {ref_auc:.3f} Ð´Ð¾ {curr_auc:.3f}).")

    return {
        "reference_auc": ref_auc,
        "current_auc": curr_auc,
        "reference_f1": ref_f1,
        "current_f1": curr_f1
    }

# --- 4. Ð›Ð¾Ð³Ð¸ÐºÐ° Ñ€ÐµÑ‚Ñ€ÐµÐ¹Ð½Ð° ---


def retrain_model():
    """Ð—Ð°Ð¿ÑƒÑÐº Ð¿Ñ€Ð¾Ñ†ÐµÐ´ÑƒÑ€Ñ‹ Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸."""
    send_alert("Ð—Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð° Ð¿Ñ€Ð¾Ñ†ÐµÐ´ÑƒÑ€Ð° Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾Ð¹ Ð³Ð¾ÑÐ¿Ð¸Ñ‚Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸.", is_critical=True)

    # Ð—Ð´ÐµÑÑŒ Ð±ÑƒÐ´ÐµÑ‚ Ð»Ð¾Ð³Ð¸ÐºÐ° Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
    # ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð·Ð°Ð¿ÑƒÑÐº Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð°
    print("Ð—Ð°Ð¿ÑƒÑÐº Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸...")


def check_and_run_retrain(data_drift_info: dict, model_performance_info: dict):
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ ÐµÐ³Ð¾ Ð¿Ñ€Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸."""
    print("\n--- ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ ---")
    retrain_needed = False
    reason = ""

    # ÐŸÐ»Ð°Ð½Ð¾Ð²Ð¾Ðµ ÐµÐ¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
    if datetime.date.today().weekday() == 0:  # ÐŸÐ¾Ð½ÐµÐ´ÐµÐ»ÑŒÐ½Ð¸Ðº
        retrain_needed = True
        reason = "ÐŸÐ»Ð°Ð½Ð¾Ð²Ð¾Ðµ ÐµÐ¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ."

    # ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð´Ñ€Ð¸Ñ„Ñ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…
    drift_percentage = data_drift_info.get('drift_percentage', 0)
    if drift_percentage > DATA_DRIFT_THRESHOLD and not retrain_needed:
        retrain_needed = True
        reason = f"ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð´Ñ€Ð¸Ñ„Ñ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… ({drift_percentage:.1%} Ñ„Ð¸Ñ‡ ÑÐ¼ÐµÑ‰ÐµÐ½Ð¾)."

    # ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð´ÐµÐ³Ñ€Ð°Ð´Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
    ref_auc = model_performance_info.get('reference_auc', -1)
    curr_auc = model_performance_info.get('current_auc', -1)
    if (ref_auc > 0 and curr_auc > 0 and
        curr_auc < ref_auc * RETRAIN_PERFORMANCE_DEGRADATION_AUC_THRESHOLD and
            not retrain_needed):
        degradation = (1 - (curr_auc / ref_auc)) * 100
        retrain_needed = True
        reason = f"ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð´ÐµÐ³Ñ€Ð°Ð´Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ (AUC ÑÐ½Ð¸Ð·Ð¸Ð»ÑÑ Ð½Ð° {degradation:.1f}%)."

    if retrain_needed:
        print(f"ÐŸÑ€Ð¸Ð½ÑÑ‚Ð¾ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¾ Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ð¸. ÐŸÑ€Ð¸Ñ‡Ð¸Ð½Ð°: {reason}")
        retrain_model()
    else:
        print("ÐŸÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð½Ðµ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ.")


# --- 5. ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½ ---
if __name__ == "__main__":
    base_dir = os.path.dirname(os.path.abspath(__file__))
    ref_data_path = os.path.join(
        base_dir, '..', '3', 'monitoring', 'data', 'reference_data.parquet')
    curr_data_path = os.path.join(
        base_dir, '..', '3', 'monitoring', 'data', 'current_data.parquet')

    try:
        ref_data = pd.read_parquet(ref_data_path)
        curr_data = pd.read_parquet(curr_data_path)
        print(
            f"Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ðµ: reference={len(ref_data)} Ð·Ð°Ð¿Ð¸ÑÐµÐ¹, current={len(curr_data)} Ð·Ð°Ð¿Ð¸ÑÐµÐ¹")
    except FileNotFoundError:
        print(
            f"ÐžÑˆÐ¸Ð±ÐºÐ°: Ð¤Ð°Ð¹Ð»Ñ‹ Ð´Ð»Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ Ð¿Ð¾ Ð¿ÑƒÑ‚ÑÐ¼:\n{ref_data_path}\n{curr_data_path}")
        print("Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ create_monitoring_data.py")
        exit()

    # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ production Ð¼Ð¾Ð´ÐµÐ»ÑŒ
    client = MlflowClient()
    try:
        latest_versions = client.get_latest_versions(
            "HospitalReadmissionModel", stages=["Production"])
        if not latest_versions:
            raise IndexError("No model versions found in Production stage.")
        prod_model_info = latest_versions[0]
        model_uri = f"models:/{prod_model_info.name}/{prod_model_info.version}"
        production_model = mlflow.pyfunc.load_model(model_uri)
        print(f"âœ… Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° production Ð¼Ð¾Ð´ÐµÐ»ÑŒ: v{prod_model_info.version}")
    except IndexError as e:
        print(
            f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {e}. Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ Ñ…Ð¾Ñ‚Ñ Ð±Ñ‹ Ð¾Ð´Ð½Ð° Ð²ÐµÑ€ÑÐ¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸Ð¼ÐµÐµÑ‚ ÑÑ‚ÐµÐ¹Ð´Ð¶ 'Production'.")
        exit()
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {e}")
        exit()

    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³
    data_drift_results = monitor_data_drift(
        ref_data.drop('readmitted_30_days', axis=1),
        curr_data.drop('readmitted_30_days', axis=1)
    )

    model_performance_results = monitor_model_performance(
        production_model,
        ref_data,
        curr_data
    )

    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
    check_and_run_retrain(data_drift_results, model_performance_results)

    print("\nâœ… ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½!")
